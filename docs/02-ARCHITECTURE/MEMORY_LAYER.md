# Comby Skill Memory Layer Design

> ğŸ’¡ **Â¿CÃ³mo Comby mejora tu flujo de trabajo?** Consulta [Workflow Comparison](../01-GETTING-STARTED/WORKFLOW_COMPARISON.md) para ver casos reales de uso (antes/despuÃ©s con grep/rg vs Comby + Memory)

## Objetivo
Crear una capa de memoria **ligera, embebida y persistente** para Comby Skill que permita:
1. **Almacenar resultados de anÃ¡lisis** de un repositorio Ãºnico a travÃ©s del tiempo
2. **Establecer relaciones semÃ¡nticas** entre patrones detectados (grafo)
3. **Buscar por similitud** y contexto usando embeddings vectoriales
4. **Entender la evoluciÃ³n** del cÃ³digo en el repositorio

## VisiÃ³n General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Comby Skill Memory Layer                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Vector Database (SQLite + Vector Extension)â”‚   â”‚
â”‚  â”‚ - Embeddings de patrones detectados        â”‚   â”‚
â”‚  â”‚ - BÃºsqueda por similitud                   â”‚   â”‚
â”‚  â”‚ - Indexado automÃ¡tico                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Graph Relations (Tablas normalizadas)      â”‚   â”‚
â”‚  â”‚ - Relaciones entre patrones                â”‚   â”‚
â”‚  â”‚ - Dependencias entre archivos              â”‚   â”‚
â”‚  â”‚ - HistÃ³rico de evoluciÃ³n                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ SQLite Database (Single File)              â”‚   â”‚
â”‚  â”‚ - Persistencia embebida                    â”‚   â”‚
â”‚  â”‚ - Sin server, sin dependencias externas    â”‚   â”‚
â”‚  â”‚ - UbicaciÃ³n: .comby/memory.db              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Arquitectura de Almacenamiento

### 1. UbicaciÃ³n de Datos
```
<project-root>/
â”œâ”€â”€ .comby/
â”‚   â”œâ”€â”€ memory.db                    # SQLite database (Ãºnico archivo)
â”‚   â”œâ”€â”€ config.json                  # ConfiguraciÃ³n de memoria
â”‚   â””â”€â”€ .gitignore                   # Excluir de Git (excepto config)
â””â”€â”€ ...
```

**Consideraciones**:
- `.comby/memory.db` NO se comitea a Git (almacenamiento local)
- `.comby/config.json` OPCIONAL: puede cometerse para compartir configuraciÃ³n
- SQLite es un Ãºnico archivo binario, sin dependencias externas

### 2. Schema del Database

#### **Tabla: `patterns` (Patrones detectados)**
```sql
CREATE TABLE patterns (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    repo_hash TEXT NOT NULL,                    -- Hash del repo para invalidar cachÃ©
    file_path TEXT NOT NULL,                    -- Ruta relativa del archivo
    pattern_type TEXT NOT NULL,                 -- 'SQL_INJECTION', 'MISSING_TYPE_HINTS', etc
    line_number INTEGER NOT NULL,               -- LÃ­nea donde se detectÃ³
    code_snippet TEXT NOT NULL,                 -- El cÃ³digo exacto
    severity TEXT NOT NULL,                     -- 'CRITICAL', 'MEDIUM', 'LOW'
    embedding BLOB,                             -- Vector embeddings (float32 array)
    detected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(file_path, pattern_type, line_number)
);

-- Ãndices para bÃºsqueda rÃ¡pida
CREATE INDEX idx_patterns_file ON patterns(file_path);
CREATE INDEX idx_patterns_type ON patterns(pattern_type);
CREATE INDEX idx_patterns_severity ON patterns(severity);
CREATE INDEX idx_patterns_timestamp ON patterns(detected_at DESC);
```

#### **Tabla: `pattern_relations` (Relaciones entre patrones - Grafo)**
```sql
CREATE TABLE pattern_relations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_pattern_id INTEGER NOT NULL,         -- Pattern A
    target_pattern_id INTEGER NOT NULL,         -- Pattern B
    relation_type TEXT NOT NULL,                -- 'depends_on', 'conflicts_with', 'same_file', 'related_function'
    confidence REAL,                            -- 0.0 a 1.0
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY(source_pattern_id) REFERENCES patterns(id) ON DELETE CASCADE,
    FOREIGN KEY(target_pattern_id) REFERENCES patterns(id) ON DELETE CASCADE,
    UNIQUE(source_pattern_id, target_pattern_id, relation_type)
);

-- Ãndices para traversal de grafo
CREATE INDEX idx_relations_source ON pattern_relations(source_pattern_id);
CREATE INDEX idx_relations_target ON pattern_relations(target_pattern_id);
CREATE INDEX idx_relations_type ON pattern_relations(relation_type);
```

#### **Tabla: `file_snapshots` (Snapshots de archivos analizados)**
```sql
CREATE TABLE file_snapshots (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    file_path TEXT NOT NULL,
    file_hash TEXT NOT NULL,                    -- Hash del contenido (SHA256)
    total_patterns INTEGER DEFAULT 0,
    critical_count INTEGER DEFAULT 0,
    medium_count INTEGER DEFAULT 0,
    low_count INTEGER DEFAULT 0,
    analyzed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(file_path, file_hash)
);

CREATE INDEX idx_snapshots_file ON file_snapshots(file_path);
CREATE INDEX idx_snapshots_analyzed ON file_snapshots(analyzed_at DESC);
```

#### **Tabla: `analysis_history` (HistÃ³rico de anÃ¡lisis)**
```sql
CREATE TABLE analysis_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    repo_state_hash TEXT,                       -- Hash del estado del repo
    total_files_analyzed INTEGER,
    total_patterns_found INTEGER,
    critical_patterns INTEGER,
    analysis_duration_ms FLOAT,
    analyzed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    notes TEXT                                  -- Anotaciones opcionalesanal
);

CREATE INDEX idx_history_analyzed ON analysis_history(analyzed_at DESC);
```

#### **Tabla: `annotations` (Anotaciones y notas del usuario)**
```sql
CREATE TABLE annotations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    pattern_id INTEGER,                         -- Relacionado a un patrÃ³n (opcional)
    file_path TEXT,
    tag TEXT,                                   -- 'false_positive', 'urgent', 'refactor_candidate', etc
    note TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY(pattern_id) REFERENCES patterns(id) ON DELETE SET NULL,
    INDEX idx_annotations_tag(tag)
);
```

---

## Capa de Vectores (Embeddings)

### 1. Estrategia de Embeddings

**OpciÃ³n A: Lightweight (Recomendada para MVP)**
- Usar embeddings simples basados en cÃ³digo
- NO requiere modelos ML complejos
- Dos estrategias:
  - **Hash-based**: Transformar cÃ³digo en vector simple (determinÃ­stico, rÃ¡pido)
  - **Sentence transformers ligero**: Si se requiere, usar modelo mÃ­nimo como `all-MiniLM-L6-v2`

**OpciÃ³n B: IntegraciÃ³n Claude AI (Futuro)**
- Usar embeddings de Claude a travÃ©s de API
- Requiere key API disponible
- Mejor calidad semÃ¡ntica
- Fallback a estrategia lightweight si no hay API key

### 2. ImplementaciÃ³n de Embeddings Simples

```python
class CodeEmbedding:
    """Genera embeddings determinÃ­sticos para cÃ³digo."""

    @staticmethod
    def embed_code_snippet(code: str, pattern_type: str) -> List[float]:
        """
        Crea un embedding simple de un snippet de cÃ³digo.

        Vector de 768 dimensiones compuesto por:
        - 200 dim: caracterÃ­sticas lÃ©xicas (palabras clave, operadores)
        - 200 dim: caracterÃ­sticas estructurales (indentaciÃ³n, complejidad)
        - 200 dim: caracterÃ­sticas semÃ¡nticas (patrÃ³n, contexto)
        - 168 dim: hash del contenido
        """

        # Feature 1: AnÃ¡lisis lÃ©xico
        lexical = extract_lexical_features(code)         # 200 dim

        # Feature 2: AnÃ¡lisis estructural
        structural = extract_structural_features(code)   # 200 dim

        # Feature 3: CaracterÃ­sticas del patrÃ³n
        semantic = extract_semantic_features(code, pattern_type)  # 200 dim

        # Feature 4: Hash del cÃ³digo (para bÃºsqueda exacta)
        content_hash = normalize_hash(code)              # 168 dim

        return np.concatenate([lexical, structural, semantic, content_hash])
```

**Ventajas**:
- âœ… DeterminÃ­stico (mismo cÃ³digo siempre genera mismo vector)
- âœ… Sin dependencias ML pesadas
- âœ… RÃ¡pido: generaciÃ³n en <1ms por snippet
- âœ… Explicable: cada dimensiÃ³n representa caracterÃ­stica especÃ­fica

### 3. BÃºsqueda por Similitud

```python
class VectorSearch:
    """BÃºsqueda semÃ¡ntica de patrones similares."""

    def find_similar_patterns(
        self,
        query_embedding: List[float],
        pattern_type: str = None,
        threshold: float = 0.75,
        limit: int = 10
    ) -> List[Dict]:
        """
        Encuentra patrones similares usando similitud del coseno.

        Args:
            query_embedding: Vector de bÃºsqueda
            pattern_type: Filtrar por tipo de patrÃ³n (opcional)
            threshold: Umbral de similitud (0.0 a 1.0)
            limit: NÃºmero mÃ¡ximo de resultados

        Returns:
            Lista de patrones similares ordenados por similitud
        """
        # SQL: SELECT patterns + COSINE SIMILARITY
        # ImplementaciÃ³n: usar sqlite3 con extensiÃ³n vectorial
```

---

## Capa de Grafo (Relaciones)

### 1. Tipos de Relaciones

```python
class RelationType:
    """Tipos de relaciones entre patrones."""

    # Relaciones semÃ¡nticas
    DEPENDS_ON = "depends_on"           # A depende de B
    CONFLICTS_WITH = "conflicts_with"   # A y B son contradictorios
    SAME_ROOT_CAUSE = "same_root_cause" # A y B vienen de mismo problema

    # Relaciones espaciales
    SAME_FILE = "same_file"             # Ambos en mismo archivo
    SAME_FUNCTION = "same_function"     # Ambos en misma funciÃ³n
    SAME_CLASS = "same_class"           # Ambos en misma clase

    # Relaciones temporales
    PRECEDES = "precedes"               # A aparece antes que B
    FIXES = "fixes"                     # A arregla el problema de B

    # Relaciones de contexto
    RELATED_TO = "related_to"           # Relacionado (general)
```

### 2. ConstrucciÃ³n AutomÃ¡tica de Relaciones

Al detectar patrones, el sistema automÃ¡ticamente establece relaciones:

```python
class GraphBuilder:
    """Construye el grafo de relaciones automÃ¡ticamente."""

    def build_relations_from_patterns(self, patterns: List[Dict]) -> List[Dict]:
        """
        Analiza patrones y establece relaciones automÃ¡ticas.

        Reglas:
        1. Si dos patrones estÃ¡n en el mismo archivo â†’ same_file
        2. Si estÃ¡n en la misma funciÃ³n â†’ same_function (parse AST)
        3. Si son del mismo tipo y similares â†’ related_to (similitud vectorial)
        4. Si una es SQL_INJECTION y otra INPUT_VALIDATION en mismo flujo â†’ depends_on
        5. Si hay AUTH_BOUNDARIES y API_ENDPOINT â†’ same_file
        """
        pass
```

### 3. Queries de Grafo

```python
class GraphQueries:
    """Queries Ãºtiles sobre el grafo."""

    def get_pattern_context(self, pattern_id: int, depth: int = 2) -> Dict:
        """
        Retorna un patrÃ³n con su contexto completo (grafo de relaciones).

        Ejemplo:
        {
            "pattern": {...},
            "related": [
                {
                    "pattern": {...},
                    "relation": "depends_on",
                    "confidence": 0.92
                }
            ],
            "dependents": [...],
            "in_same_file": [...]
        }
        """
        pass

    def find_connected_components(self, pattern_type: str = None) -> List[List[int]]:
        """
        Encuentra clusters de patrones conectados (componentes conexas).
        Ãštil para entender problemas relacionados.
        """
        pass

    def get_critical_path(self) -> List[int]:
        """
        Retorna el camino crÃ­tico: secuencia de patrones que deben arreglarse
        en orden de dependencias.
        """
        pass
```

---

## Interfaz de la Capa de Memoria

### 1. Clase Principal: `MemoryManager`

```python
class MemoryManager:
    """
    Gestor central de la capa de memoria.

    Responsabilidades:
    - Inicializar/migrar database
    - Almacenar y recuperar patrones
    - Construir y consultar grafo
    - Manejar embeddings
    """

    def __init__(self, repo_path: str, db_path: str = None):
        """
        Args:
            repo_path: Ruta al repositorio
            db_path: Ruta a la base de datos (default: repo/.comby/memory.db)
        """
        self.repo_path = Path(repo_path)
        self.db_path = Path(db_path or repo_path / ".comby" / "memory.db")
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._initialize_database()

    # === OPERACIONES BÃSICAS ===

    def save_analysis_results(
        self,
        file_path: str,
        patterns: List[Dict[str, Any]]
    ) -> None:
        """
        Guarda los resultados de anÃ¡lisis de un archivo.

        Args:
            file_path: Ruta relativa del archivo analizado
            patterns: Lista de patrones detectados
        """
        pass

    def get_patterns(
        self,
        file_path: str = None,
        pattern_type: str = None,
        severity: str = None,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """
        Recupera patrones con filtros opcionales.
        """
        pass

    # === OPERACIONES DE VECTORES ===

    def find_similar_patterns(
        self,
        pattern_id: int,
        threshold: float = 0.75,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Encuentra patrones similares a uno dado.
        """
        pass

    def semantic_search(
        self,
        query: str,
        pattern_type: str = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        BÃºsqueda semÃ¡ntica: busca patrones por descripciÃ³n natural.

        Ejemplo:
        memory.semantic_search("SQL injection with user input")
        """
        pass

    # === OPERACIONES DE GRAFO ===

    def get_pattern_context(
        self,
        pattern_id: int,
        depth: int = 2
    ) -> Dict[str, Any]:
        """
        Retorna un patrÃ³n con su contexto relacional completo.
        """
        pass

    def get_connected_patterns(self, pattern_id: int) -> List[Dict]:
        """
        Retorna todos los patrones conectados a uno dado.
        """
        pass

    def analyze_dependencies(self) -> Dict[str, Any]:
        """
        Analiza el grafo completo de dependencias.

        Retorna:
        {
            "clusters": [...],
            "critical_paths": [...],
            "cycles": [...],
            "orphaned": [...]
        }
        """
        pass

    # ===OPERACIONES DE HISTÃ“RICO ===

    def get_evolution(self, file_path: str) -> List[Dict]:
        """
        Retorna la evoluciÃ³n de patrones en un archivo a travÃ©s del tiempo.
        """
        pass

    def compare_snapshots(self, snapshot1_id: int, snapshot2_id: int) -> Dict:
        """
        Compara dos anÃ¡lisis (snapshots) del repositorio.

        Retorna:
        {
            "new_patterns": [...],
            "fixed_patterns": [...],
            "changed_severity": [...]
        }
        """
        pass

    # === ANOTACIONES ===

    def annotate_pattern(
        self,
        pattern_id: int,
        tag: str,
        note: str = None
    ) -> None:
        """
        AÃ±ade anotaciÃ³n a un patrÃ³n.

        Tags comunes:
        - 'false_positive': No es realmente un problema
        - 'urgent': Arreglar inmediatamente
        - 'refactor_candidate': Buen candidato para refactor
        - 'accepted_risk': Riesgo aceptado
        """
        pass

    def get_annotations(self, pattern_id: int = None) -> List[Dict]:
        """
        Recupera anotaciones, opcionalmente filtradas.
        """
        pass

    # === MANTENIMIENTO ===

    def clear(self) -> None:
        """Limpia toda la base de datos."""
        pass

    def export_json(self, output_path: str) -> None:
        """Exporta la memoria a JSON (para debugging/sharing)."""
        pass

    def import_json(self, input_path: str) -> None:
        """Importa memoria desde JSON."""
        pass

    def get_stats(self) -> Dict[str, Any]:
        """
        Retorna estadÃ­sticas de la memoria.

        {
            "total_patterns": 123,
            "by_severity": {"CRITICAL": 15, "MEDIUM": 60, "LOW": 48},
            "by_type": {"SQL_INJECTION": 10, ...},
            "files_analyzed": 45,
            "last_analysis": "2026-01-30T10:59:49Z"
        }
        """
        pass
```

### 2. IntegraciÃ³n con CLI

```bash
# Comandos nuevos de la CLI

# Ver patrones guardados
$ comby-skill memory patterns --type SQL_INJECTION --severity CRITICAL

# Ver patrones similares a uno dado
$ comby-skill memory similar --pattern-id 42

# BÃºsqueda semÃ¡ntica
$ comby-skill memory search "user input in database query"

# Ver contexto de un patrÃ³n
$ comby-skill memory context --pattern-id 42

# Analizar dependencias
$ comby-skill memory analyze

# Ver evoluciÃ³n de un archivo
$ comby-skill memory history --file src/auth.py

# Comparar dos anÃ¡lisis
$ comby-skill memory compare --snapshot-1 1 --snapshot-2 2

# Anotar un patrÃ³n
$ comby-skill memory annotate --pattern-id 42 --tag "false_positive" --note "This is a parameterized query"

# Exportar/importar
$ comby-skill memory export --output memory.json
$ comby-skill memory import --input memory.json

# EstadÃ­sticas
$ comby-skill memory stats
```

---

## Consideraciones de ImplementaciÃ³n

### 1. TecnologÃ­as

**SQLite**
- âœ… Ligero, embebido, sin servidor
- âœ… ACID, transacciones, Ã­ndices
- âœ… Soporte para extensiones
- âŒ No paralelizaciÃ³n masiva (no aplica aquÃ­)

**ExtensiÃ³n Vectorial: `sqlite-vec`**
- ExtensiÃ³n SQLite para operaciones vectoriales
- Soporte para bÃºsqueda por similitud (coseno, euclidiana)
- Indexado HNSW automÃ¡tico
- URL: https://github.com/asg017/sqlite-vec

**Embeddings**
- OpciÃ³n MVP: Hash-based + caracterÃ­sticas simples (768 dim, ~3KB por patrÃ³n)
- OpciÃ³n futura: Sentence transformers o Claude embeddings

### 2. Rendimiento

**TamaÃ±o de Database**
- Por patrÃ³n: ~5KB (incluidos embeddings)
- Para 1000 patrones: ~5MB
- Para 10,000 patrones: ~50MB
- â†’ Escalable a proyectos medianos sin problema

**Tiempo de Query**
- BÃºsqueda por tipo/severidad: <10ms
- BÃºsqueda vectorial (con Ã­ndice): <50ms
- Traversal de grafo (depth 2): <100ms
- â†’ Suficientemente rÃ¡pido para interactividad

### 3. Integridad de Datos

**InvalidaciÃ³n de CachÃ©**
```python
# Si el repo cambiÃ³, datos podrÃ­an estar obsoletos
repo_hash = compute_repo_hash()  # Hash de .git/HEAD + archivos principales
stored_hash = get_stored_repo_hash()

if repo_hash != stored_hash:
    # Opcional: invalidar todo
    # O: marcar patrones como "potentially_stale"
```

**DeduplicaciÃ³n**
```sql
-- Evitar duplicados exactos (mismo archivo, lÃ­nea, tipo)
UNIQUE(file_path, pattern_type, line_number)
```

### 4. MigraciÃ³n de Datos

```python
class DatabaseMigration:
    """Manejo de versiones de schema."""

    # v1.0: Schema inicial
    # v1.1: Agregar tabla de anotaciones
    # v2.0: Agregar tabla de historia de anÃ¡lisis

    def migrate(self, from_version: str, to_version: str) -> None:
        """Ejecuta migraciones necesarias."""
        pass
```

---

## Casos de Uso

### 1. "Mostrame los problemas SQL injection similares"

```python
# Usuario: comby-skill memory similar --pattern-id 5

pattern = memory.get_pattern(5)  # SQL_INJECTION en lÃ­nea 42
similar = memory.find_similar_patterns(5, threshold=0.7)

# Resultado: muestra 8 patrones SQL injection con cÃ³digo similar
# Ãštil para entender si es patrÃ³n repetido â†’ refactor
```

### 2. "Â¿QuÃ© patrones estÃ¡n relacionados?"

```python
# Usuario: comby-skill memory context --pattern-id 42

result = memory.get_pattern_context(42, depth=2)

# Resultado:
# {
#   "pattern": {id: 42, type: "SQL_INJECTION", ...},
#   "related": [
#     {pattern: {id: 10, type: "INPUT_VALIDATION"}, relation: "depends_on"},
#     {pattern: {id: 55, type: "SQL_INJECTION"}, relation: "same_file"}
#   ],
#   "dependents": [...]
# }
```

### 3. "Mostrame la evoluciÃ³n en este archivo"

```python
# Usuario: comby-skill memory history --file src/auth.py

history = memory.get_evolution("src/auth.py")

# Resultado: Timeline de patrones detectados en ese archivo
# - 2026-01-15: SQL_INJECTION detectado
# - 2026-01-20: Arreglado (removed from latest snapshot)
# - 2026-01-25: Nuevo MISSING_TYPE_HINTS detectado
```

### 4. "Â¿CuÃ¡les son los problemas crÃ­ticos que debo arreglar primero?"

```python
# Usuario: comby-skill memory analyze

analysis = memory.analyze_dependencies()

# Resultado:
# - Critical path: [pattern_5 â†’ pattern_12 â†’ pattern_8]
#   (arreglar en este orden)
# - Clusters: 3 clusters de problemas relacionados
# - Orphaned: 2 patrones aislados (bajo prioridad)
```

---

## IntegraciÃ³n con PatternMatcher

### 1. Flujo de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  analyze_file()     â”‚
â”‚  (CLI command)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PatternMatcher.detect_*()       â”‚
â”‚ - SQL injection                 â”‚
â”‚ - Type hints                    â”‚
â”‚ - [Future patterns]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MemoryManager.save_analysis()   â”‚
â”‚ - Guardar patrones              â”‚
â”‚ - Generar embeddings            â”‚
â”‚ - Construir relaciones          â”‚
â”‚ - Actualizar Ã­ndices            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Display results      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ModificaciÃ³n MÃ­nima de PatternMatcher

```python
class PatternMatcher:
    def __init__(self, memory_manager: MemoryManager = None):
        self.memory = memory_manager

    def detect_sql_injection(self, code: str) -> List[Dict[str, Any]]:
        matches = [...]  # DetecciÃ³n actual

        if self.memory:
            # Generar embeddings
            for match in matches:
                match['embedding'] = self.memory.embed_code(
                    match['code'],
                    'SQL_INJECTION'
                )

        return matches
```

---

## ConfiguraciÃ³n del Proyecto

### 1. `.comby/config.json` (Opcional)

```json
{
  "memory": {
    "enabled": true,
    "vector_embeddings": "lightweight",
    "auto_build_relations": true,
    "retention_days": null,
    "export_on_analysis": false
  },
  "patterns": {
    "track_evolution": true,
    "deduplicate": true
  }
}
```

### 2. `.gitignore` Updates

```
# Comby Skill memory (local only)
.comby/memory.db
.comby/memory.db-*
.comby/*.tmp
```

---

## Roadmap de ImplementaciÃ³n

**Phase 1 (MVP)**: Core memory layer
- âœ“ SQLite schema bÃ¡sico
- âœ“ MemoryManager clase principal
- âœ“ Guardar/recuperar patrones
- âœ“ Embeddings determinÃ­sticos simples
- âœ“ BÃºsqueda por similitud bÃ¡sica

**Phase 2**: Grafo y relaciones
- âœ“ Tabla de relaciones
- âœ“ GraphBuilder automÃ¡tico
- âœ“ Queries de grafo bÃ¡sicas
- âœ“ AnÃ¡lisis de dependencias

**Phase 3**: Anotaciones e histÃ³rico
- âœ“ Tabla de anotaciones
- âœ“ Snapshots y comparaciÃ³n
- âœ“ EvoluciÃ³n temporal

**Phase 4 (Future)**: IntegraciÃ³n avanzada
- âœ“ Embeddings de Claude
- âœ“ BÃºsqueda semÃ¡ntica mejorada
- âœ“ Reportes visuales
- âœ“ SincronizaciÃ³n multi-repo (descartado: enfoque single-repo)

---

## Conclusiones

Esta arquitectura proporciona:

1. **Persistencia ligera**: SQLite, un archivo, sin dependencias externas
2. **SemÃ¡ntica**: Embeddings + bÃºsqueda por similitud
3. **Relaciones**: Grafo de dependencias entre patrones
4. **Escalabilidad**: Rendimiento mantenido hasta 10K+ patrones
5. **Simplicidad**: IntegraciÃ³n mÃ­nima con cÃ³digo existente
6. **Extensibilidad**: FÃ¡cil agregar nuevas tablas/queries

El diseÃ±o **prioriza un Ãºnico repositorio a la vez**, evitando complejidades de multi-repo. Cada repositorio obtiene su propia `.comby/memory.db` independiente.

**Listo para pasar a implementaciÃ³n cuando lo autorice el usuario.**
